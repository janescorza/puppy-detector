## Unleash Your Inner Dog Detective ğŸ¶ğŸ•µï¸â€â™‚ï¸ with This Deep Learning Puppy Detector!âœ¨ğŸ¾

This repository houses the code for a **puppy detector** I have built entirely from scratch using **Python and my recently acquired Deep Learning skills**. This project shows how you could **distinguish between images of genuine puppies and imposters** (other animals or objects) using a neural network model. But the true purpose is to **allow you to explore the inner workings of a neural network** built from scratch using Python.

### ğŸ¤” Why Build It From Scratch? ğŸ¤”

This project goes beyond using pre-built libraries like TensorFlow. Instead, it focuses on understanding the core principles of neural networks. Building it from scratch allowed me to:

* ğŸ’¡**Demonstrate My Core Understanding**ğŸ’¡: This project demonstrates my understanding of neural network implementation, showcasing my learning journey.
* âš™ï¸**Grasp the Intricate Workings of Neural Networks**âš™ï¸: Understanding the "how" and "why" behind neural networks empowers me to optimize them effectively.
* ğŸ”¨**Experiment and Refine**ğŸ”¨: Understanding the core mechanics enables me to explore diverse optimization techniques and fine-tune the model for superior performance.

But most importantly, for you as a reader:
* ğŸ› **Tailored Learning Experience**ğŸ› : I invite you to dive into the code and see exactly how each part of the network interacts. This is an open invitation to tweak, experiment, and learn from direct interaction with neural mechanisms.
* ğŸ“š**Educational Outreach**ğŸ“š: I am here to discuss and explain any part of this project, so feel **free to reach out so we can have a chat about it**. Whether you're a beginner or looking to brush up your knowledge on how a neural networks works at its core, this repository can be the resource for you.

#### âœ¨Key Optimizations you will findâœ¨:

* **He initialization** for weights : This sets weights with a standard deviation that's more suitable for ReLU activations, helping avoid "dying neurons" and improving convergence speed.

* **Adam optimizer** for efficient updates : Adam combines the benefits of momentum and adaptive learning rates for faster and smoother convergence, often outperforming basic gradient descent.

* **Mini-batch gradient descent** (Breaking data into smaller chunks): This enables faster updates and often improves generalization, as the model sees a more diverse set of examples in each iteration.

### ğŸ¶ğŸ’»ğŸš€ Ready to Explore? ğŸ¶ğŸ’»ğŸš€
Then dive into the code, tweak it, break it, and learn from it. If you have questions, suggestions, or need clarification on any aspect, don't hesitate to reach out. Let's push the boundaries of what we can learn from neural networks, one line of code at a time!

**Getting Started:**

1. **Clone the repository:**
   ```bash
   git clone https://github.com/janescorza/puppy-detector.git
   ```
2. **Install dependencies:**
   ```bash
   pip install -r requirements.txt
   ```
3. **Run the script:**
   ```bash
   python3 main.py
   ```

### **Learning from Limitations ğŸš§ğŸ“**

The journey of developing this neural network from scratch has been **immensely educational for me, allowing me to work hands-on with many concepts I have been learning**. But at the same time, revealing both the limitations of simple architectures for complex image classification tasks. Hereâ€™s why this model remains a very important part of the learning curve:

* **Reflective Learning**: Through optimizing and refining this model, *Iâ€™ve gained deep insights into neural network mechanics at a practical level*. This repository stands as a testament to the learning that occurs when pushing the boundaries of what simple models can achieve, **making the commit history and code structure a valuable reference of the evolution**.

* **Educational Milestone**: While this network has shown its limits in scalability and performance on a laptop compared to more specialized and efficient architectures like CNNs, it serves as a **perfect example for discussions on neural network design and optimization**. Each component of this model **invites the curious to tweak and play**: *what happens if we tweak the learning rate, add more layers, or change activation functions...*

* **Paving the Way for My Exploration**: Recognizing the constraints of this model has **set the stage for my next venture into implementing a convolutional neural network (CNNs)**. Using frameworks like TensorFlow or PyTorch, I plan to explore and demonstrate how CNNs can more effectively tackle the problem of image classification, providing a robust platform for both learning-by-doing and applying all that I have learned in the Deep Learning course.

* **Invitation to Collaboration**: I welcome you to join me in this learning journey. Feel free to fork the repository, experiment with the code, and provide feedback. 


### âœ¨ Continuing the Learning Journey âœ¨
Moving forward, I am excited to dive into CNNs, NLP and more... and share those experiences, drawing comparisons and highlighting what I find the most interesting in this journey of exploration. 

*Stay tuned for more updates and explorations in deep learning!*